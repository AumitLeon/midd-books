{
  "_args": [
    [
      "node-webcrawler",
      "C:\\Users\\Aumit\\Documents\\Dev\\Textbook"
    ]
  ],
  "_from": "node-webcrawler@latest",
  "_id": "node-webcrawler@0.7.3",
  "_inCache": true,
  "_installable": true,
  "_location": "/node-webcrawler",
  "_nodeVersion": "5.8.0",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/node-webcrawler-0.7.3.tgz_1460961296203_0.6846184977330267"
  },
  "_npmUser": {
    "email": "mike442144@hotmail.com",
    "name": "mike442144"
  },
  "_npmVersion": "3.7.3",
  "_phantomChildren": {},
  "_requested": {
    "name": "node-webcrawler",
    "raw": "node-webcrawler",
    "rawSpec": "",
    "scope": null,
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/node-webcrawler/-/node-webcrawler-0.7.3.tgz",
  "_shasum": "56536927987fcf7cf22db3afcef67d15a6af29c7",
  "_shrinkwrap": null,
  "_spec": "node-webcrawler",
  "_where": "C:\\Users\\Aumit\\Documents\\Dev\\Textbook",
  "author": {
    "name": "Mike Chen"
  },
  "bugs": {
    "url": "https://github.com/bda-research/node-webcrawler/issues"
  },
  "dependencies": {
    "bottleneck": "1.9.1",
    "charset-parser": "^0.2.0",
    "cheerio": "0.19.0",
    "generic-pool": "2.2.0",
    "iconv": "*",
    "iconv-lite": "0.4.8",
    "lodash": "3.8.0",
    "request": "2.67.0",
    "seenreq": "^0.1.7"
  },
  "description": "Crawler is a web spider written with Nodejs. It gives you the full power of jQuery on the server to parse a big number of pages as they are downloaded, asynchronously",
  "devDependencies": {
    "chai": "2.3.0",
    "jsdom": "3.1.2",
    "mocha": "2.2.5",
    "mocha-testdata": "1.1.0",
    "sinon": "1.14.1"
  },
  "directories": {
    "test": "tests"
  },
  "dist": {
    "shasum": "56536927987fcf7cf22db3afcef67d15a6af29c7",
    "tarball": "https://registry.npmjs.org/node-webcrawler/-/node-webcrawler-0.7.3.tgz"
  },
  "gitHead": "8cc03e00da37677e08f9650cc8111693b15dfedf",
  "homepage": "https://github.com/bda-research/node-webcrawler",
  "keywords": [
    "crawler",
    "crawling",
    "dom",
    "javascript",
    "jquery",
    "scraper",
    "scraping",
    "spider"
  ],
  "license": "ISC",
  "main": "./lib/crawler.js",
  "maintainers": [
    {
      "name": "mike442144",
      "email": "mike442144@hotmail.com"
    }
  ],
  "name": "node-webcrawler",
  "optionalDependencies": {
    "iconv": "*"
  },
  "readme": "ERROR: No README data found!",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/bda-research/node-webcrawler.git"
  },
  "scripts": {
    "test": "./node_modules/mocha/bin/mocha --reporter spec --bail --timeout 10000 tests/*.js"
  },
  "version": "0.7.3"
}
